{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24922486",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import cv2, os, math, time, ast\n",
    "from datetime import datetime\n",
    "import time\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from typing import List\n",
    "from torchvision.ops import box_iou\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection import FasterRCNN_ResNet50_FPN_Weights\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchinfo import summary\n",
    "from torchvision.models.detection.backbone_utils import resnet_fpn_backbone\n",
    "from torchvision.models import ResNet101_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ZzzvYEER-n6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17898,
     "status": "ok",
     "timestamp": 1657114172158,
     "user": {
      "displayName": "su lin",
      "userId": "17083638299800112057"
     },
     "user_tz": -60
    },
    "id": "0ZzzvYEER-n6",
    "outputId": "860526a2-591c-4609-e9fa-4bc9ead22ab6"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/gdrive', force_remount=True)\n",
    "#% cd /content/gdrive/MyDrive/datasets/gbr_cots/\n",
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4decabc9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4274,
     "status": "ok",
     "timestamp": 1657114178482,
     "user": {
      "displayName": "su lin",
      "userId": "17083638299800112057"
     },
     "user_tz": -60
    },
    "id": "4decabc9",
    "outputId": "92b9582d-146b-4ce0-e524-479bedec7a26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of train data with annotations: (4919, 4)\n",
      "shape of training data: (4427, 4)\n",
      "shape of validation data: (492, 4)\n",
      "Min number of bboxs per image: 1\n",
      "Max number of bboxs per image: 18\n",
      "Max width of all bboxs: 243\n",
      "Max height of all bboxs: 222\n",
      "Min width of all bboxs: 17\n",
      "Min height of all bboxs: 13\n",
      "1.47% of all aspect ratios greater than 2\n",
      "1.15% of all aspect ratios less than 0.25\n"
     ]
    }
   ],
   "source": [
    "base_dir = 'h:/Python/ob'\n",
    "train_csv = os.path.join(base_dir, \"train.csv\")\n",
    "train_df = pd.read_csv(train_csv)\n",
    "train_df[\"img_path\"] = os.path.join(base_dir, \"train_images\") + \"/video_\" + train_df.video_id.astype(str) + \"/\" + train_df.video_frame.astype(str) + \".jpg\"\n",
    "train_df[\"annotations\"] = train_df[\"annotations\"].apply(eval)\n",
    "train_df[\"a_count\"] = train_df[\"annotations\"].apply(len)\n",
    "train_df = train_df.drop(columns=['video_id', 'sequence', 'video_frame', 'sequence_frame'])\n",
    "train_df_positive = train_df[train_df['a_count'] != 0]\n",
    "train_df_positive= train_df_positive.reset_index(drop=True)\n",
    "print('shape of train data with annotations:', train_df_positive.shape)\n",
    "\n",
    "train_df_ratio = (train_df_positive.set_index('image_id').explode('annotations').\n",
    "                  apply(lambda row: pd.Series(row['annotations']), axis=1).reset_index())\n",
    "train_df_ratio['aspect_ratio'] = train_df_ratio['height']/train_df_ratio['width']\n",
    "\n",
    "train_df_p, val_df_p = train_test_split(train_df_positive, test_size=0.1, random_state=0)\n",
    "print('shape of training data:', train_df_p.shape)\n",
    "print('shape of validation data:', val_df_p.shape)\n",
    "print('Min number of bboxs per image:', min(train_df_positive.a_count))\n",
    "print('Max number of bboxs per image:', max(train_df_positive.a_count))\n",
    "print('Max width of all bboxs:', max(train_df_ratio.width))\n",
    "print('Max height of all bboxs:', max(train_df_ratio.height))\n",
    "print('Min width of all bboxs:', min(train_df_ratio.width))\n",
    "print('Min height of all bboxs:', min(train_df_ratio.height))\n",
    "\n",
    "print('{:.2%} of all aspect ratios greater than 2'.\n",
    "      format(train_df_ratio[train_df_ratio['aspect_ratio'] > 1.5].shape[0]/train_df_ratio.shape[0]))\n",
    "\n",
    "print('{:.2%} of all aspect ratios less than 0.25'.\n",
    "      format(train_df_ratio[train_df_ratio['aspect_ratio'] < 0.5].shape[0]/train_df_ratio.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a1fef19",
   "metadata": {
    "executionInfo": {
     "elapsed": 260,
     "status": "ok",
     "timestamp": 1657122674568,
     "user": {
      "displayName": "su lin",
      "userId": "17083638299800112057"
     },
     "user_tz": -60
    },
    "id": "0a1fef19"
   },
   "outputs": [],
   "source": [
    "class COTS_Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df_img, df_bbox, original_size=(1280, 720), resize_size=(1280, 720)):\n",
    "        self.df_img = df_img\n",
    "        self.df_bbox = df_bbox\n",
    "        self.orginal_size = original_size\n",
    "        self.resize_size = resize_size\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        # load images and masks\n",
    "        row = self.df_img.iloc[idx]\n",
    "        img = Image.open(row['img_path']).convert('RGB')\n",
    "        if True: \n",
    "            img = np.array(img)/255.\n",
    "        else:\n",
    "            img = np.array(img.resize((self.w, self.h), resample=Image.BILINEAR))/255.\n",
    "        data = self.df_bbox[self.df_bbox['image_id'] == row['image_id']]\n",
    "        labels = ['cots'] * data.shape[0]\n",
    "        data = data[['x','y','width','height']].values\n",
    "        area = data[:, 2] * data[:, 3]\n",
    "        data[:,[2]] += data[:,[0]]\n",
    "        data[:,[3]] += data[:,[1]]\n",
    "        boxes = data.astype(np.uint32).tolist() # convert to absolute coordinates\n",
    "        # torch FRCNN expects ground truths as a dictionary of tensors\n",
    "        iscrowd = torch.zeros((data.shape[0],), dtype=torch.int64)\n",
    "        target = {}\n",
    "        target[\"boxes\"] = torch.Tensor(boxes).float()\n",
    "        target[\"labels\"] = torch.Tensor([1 for i in labels]).long()\n",
    "        target[\"image_id\"] = torch.tensor([idx])\n",
    "        target[\"area\"] = torch.Tensor(area).float()\n",
    "        target[\"iscrowd\"] = iscrowd\n",
    "\n",
    "        img = torch.tensor(img).permute(2,0,1)\n",
    "        return img.to(device).float(), target\n",
    "    \n",
    "    def collate_fn(self, batch):\n",
    "        return tuple(zip(*batch)) \n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df_img.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9a475a6",
   "metadata": {
    "executionInfo": {
     "elapsed": 271,
     "status": "ok",
     "timestamp": 1657122676865,
     "user": {
      "displayName": "su lin",
      "userId": "17083638299800112057"
     },
     "user_tz": -60
    },
    "id": "e9a475a6"
   },
   "outputs": [],
   "source": [
    "train_ds = COTS_Dataset(train_df_p, train_df_ratio)\n",
    "test_ds = COTS_Dataset(val_df_p, train_df_ratio)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=4, collate_fn=train_ds.collate_fn, drop_last=False)\n",
    "test_loader = DataLoader(test_ds, batch_size=4, collate_fn=test_ds.collate_fn, drop_last=False)\n",
    "\n",
    "# test\n",
    "# img, tgt = next(iter(test_loader))   \n",
    "# print(img[0].shape)\n",
    "# print(tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29ec51cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sl4n21\\Miniconda3\\envs\\myenv\\lib\\site-packages\\torchvision\\models\\_utils.py:135: UserWarning: Using 'backbone_name' as positional parameter(s) is deprecated since 0.13 and will be removed in 0.15. Please use keyword parameter(s) instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FasterRCNN(\n",
       "  (transform): GeneralizedRCNNTransform(\n",
       "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
       "  )\n",
       "  (backbone): BackboneWithFPN(\n",
       "    (body): IntermediateLayerGetter(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): FrozenBatchNorm2d(64, eps=1e-05)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=1e-05)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=1e-05)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=1e-05)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=1e-05)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=1e-05)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=1e-05)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=1e-05)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=1e-05)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(512, eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=1e-05)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=1e-05)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=1e-05)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=1e-05)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=1e-05)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=1e-05)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(1024, eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (6): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (7): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (8): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (9): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (10): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (11): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (12): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (13): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (14): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (15): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (16): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (17): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (18): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (19): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (20): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (21): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (22): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=1e-05)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=1e-05)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(2048, eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=1e-05)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=1e-05)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=1e-05)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=1e-05)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fpn): FeaturePyramidNetwork(\n",
       "      (inner_blocks): ModuleList(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (layer_blocks): ModuleList(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (extra_blocks): LastLevelMaxPool()\n",
       "    )\n",
       "  )\n",
       "  (rpn): RegionProposalNetwork(\n",
       "    (anchor_generator): AnchorGenerator()\n",
       "    (head): RPNHead(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (roi_heads): RoIHeads(\n",
       "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
       "    (box_head): TwoMLPHead(\n",
       "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
       "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (box_predictor): FastRCNNPredictor(\n",
       "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
       "      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.models.detection.anchor_utils import AnchorGenerator\n",
    "min_size = 810\n",
    "max_size = 1440\n",
    "df = pd.read_csv(base_dir + '/train_models/cots_mean_std.csv', header=0)\n",
    "image_mean = df['total_mean'].tolist()\n",
    "image_std = df['total_std'].tolist()\n",
    "\n",
    "anchor_sizes = ((8,), (16,), (32,), (64,), (128,))\n",
    "aspect_ratios = ((0.5, 1.0, 2.0),) * len(anchor_sizes)\n",
    "anchor_generator = AnchorGenerator(anchor_sizes, aspect_ratios)\n",
    "backbone = resnet_fpn_backbone('resnet101', weights=ResNet101_Weights.IMAGENET1K_V2, trainable_layers=2)\n",
    "\n",
    "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "#model = fasterrcnn_resnet50_fpn(weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT) \n",
    "#image_mean=image_mean, image_std =image_std, anchor_generator=anchor_generator, \n",
    "\n",
    "#in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "#model.roi_heads.box_predictor = FastRCNNPredictor(in_features, 2)\n",
    "\n",
    "model = FasterRCNN(backbone, num_classes=2)\n",
    "no_of_epochs = 12\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.005,momentum=0.9, weight_decay=0.0005)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "model.to(device)\n",
    "\n",
    "#summary(model, input_size=(1, 3, 720, 1280))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fd8db8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 4173473,
     "status": "error",
     "timestamp": 1657118771552,
     "user": {
      "displayName": "su lin",
      "userId": "17083638299800112057"
     },
     "user_tz": -60
    },
    "id": "f8fd8db8",
    "outputId": "bdbcb787-c021-4c4f-f68d-5d393bae0576"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1/12_Train loss: 0.285, Val loss: 0.246 --> ./fasterrcnn_resnet101_fpn_free_last2_e1.bin time_used: 1541.92 seconds\n",
      "Epoch  2/12_Train loss: 0.228, Val loss: 0.234 --> ./fasterrcnn_resnet101_fpn_free_last2_e2.bin time_used: 1528.98 seconds\n",
      "Epoch  3/12_Train loss: 0.191, Val loss: 0.205 --> ./fasterrcnn_resnet101_fpn_free_last2_e3.bin time_used: 1545.39 seconds\n",
      "Epoch  4/12_Train loss: 0.154, Val loss: 0.183 --> ./fasterrcnn_resnet101_fpn_free_last2_e4.bin time_used: 1545.08 seconds\n"
     ]
    }
   ],
   "source": [
    "time_start = datetime.now()\n",
    "loss = []\n",
    "loss_box_reg = []\n",
    "loss_clf = []\n",
    "loss_rpn_box = []\n",
    "loss_obj = []\n",
    "lr = []\n",
    "\n",
    "loss_val = []\n",
    "loss_box_reg_val = []\n",
    "loss_clf_val = []\n",
    "loss_rpn_box_val = []\n",
    "loss_obj_val = []\n",
    "\n",
    "n_batches, n_batches_val = len(train_loader), len(test_loader)\n",
    "\n",
    "for epoch in range(no_of_epochs):\n",
    "    time_begin = time.time()\n",
    "    loss_accum = 0\n",
    "    loss_reg_accum = 0 \n",
    "    loss_cls_accum = 0 \n",
    "    loss_rpn_box_reg_accum = 0 \n",
    "    loss_objectness_accum = 0 \n",
    "    \n",
    "    val_loss_accum = 0 \n",
    "    val_loss_reg_accum = 0\n",
    "    val_loss_cls_accum = 0 \n",
    "    val_loss_rpn_box_reg_accum = 0 \n",
    "    val_loss_objectness_accum = 0 \n",
    "    \n",
    "    for batch_idx, (images, targets) in enumerate(train_loader, 1):\n",
    "        \n",
    "        images = list(image.to(DEVICE) for image in images)\n",
    "        targets = [{k: v.to(DEVICE) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        # Predict\n",
    "        loss_dict = model(images, targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        loss_reg = loss_dict['loss_box_reg'].item()\n",
    "        loss_cls = loss_dict['loss_classifier'].item()\n",
    "        loss_rpn_box_reg = loss_dict['loss_rpn_box_reg'].item()\n",
    "        loss_objectness = loss_dict['loss_objectness'].item()\n",
    "        loss_accum += losses.item()\n",
    "        loss_reg_accum += loss_reg\n",
    "        loss_cls_accum += loss_cls\n",
    "        loss_rpn_box_reg_accum += loss_rpn_box_reg\n",
    "        loss_objectness_accum += loss_objectness\n",
    "        \n",
    "        # Back-prop\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "        lr_epoch = lr_scheduler.get_last_lr()[0]\n",
    "\n",
    "    \n",
    "    # update the learning rate\n",
    "    if lr_scheduler is not None:\n",
    "        lr_scheduler.step()\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, targets) in enumerate(test_loader, 1):\n",
    "            images = list(image.to(DEVICE) for image in images)\n",
    "            targets = [{k: v.to(DEVICE) for k, v in t.items()} for t in targets]\n",
    "            \n",
    "            val_loss_dict = model(images, targets)\n",
    "            val_batch_loss = sum(loss for loss in val_loss_dict.values()).item()\n",
    "            val_loss_reg = val_loss_dict['loss_box_reg'].item()\n",
    "            val_loss_cls = val_loss_dict['loss_classifier'].item()\n",
    "            val_loss_rpn_box_reg = val_loss_dict['loss_rpn_box_reg'].item()\n",
    "            val_loss_objectness = val_loss_dict['loss_objectness'].item()\n",
    "            val_loss_accum += val_batch_loss\n",
    "            val_loss_reg_accum += val_loss_reg\n",
    "            val_loss_cls_accum += val_loss_cls\n",
    "            val_loss_rpn_box_reg_accum += loss_rpn_box_reg\n",
    "            val_loss_objectness_accum += loss_objectness\n",
    "    \n",
    "    train_loss = loss_accum / n_batches\n",
    "    val_loss = val_loss_accum / n_batches_val\n",
    "    loss.append(train_loss)\n",
    "    loss_val.append(val_loss)\n",
    "    lr.append(lr_epoch)\n",
    "    \n",
    "    loss_box_reg.append(loss_reg_accum/n_batches)\n",
    "    loss_clf.append(loss_cls_accum/n_batches)\n",
    "    loss_rpn_box.append(loss_rpn_box_reg_accum/n_batches)\n",
    "    loss_obj.append(loss_objectness_accum/n_batches)\n",
    "    \n",
    "    loss_box_reg_val.append(val_loss_reg_accum/n_batches_val)\n",
    "    loss_clf_val.append(val_loss_cls_accum/n_batches_val)\n",
    "    loss_rpn_box_val.append(val_loss_rpn_box_reg_accum/n_batches_val)\n",
    "    loss_obj_val.append(val_loss_objectness_accum/n_batches_val)\n",
    "    \n",
    "    # Save model\n",
    "    chk_name = f'./fasterrcnn_resnet101_fpn_free_last2_e{epoch+1}.bin'\n",
    "    torch.save(model.state_dict(), chk_name)\n",
    "    \n",
    "    elapsed = time.time() - time_begin\n",
    "    dict_01 = {'Epoch': epoch+1, 'no_of_epochs': no_of_epochs, \n",
    "               'train_loss': train_loss, 'val_loss': val_loss, \n",
    "               'chk_name': chk_name, 'time_used': elapsed}\n",
    "    print('Epoch {Epoch: 2d}/{no_of_epochs:2d}_Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f} --> {chk_name} time_used: {time_used:.2f} seconds'.format(**dict_01))\n",
    "\n",
    "print('Training Completed and time used: ', datetime.now() - time_start)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3HiqdtZoC8Sf",
   "metadata": {
    "executionInfo": {
     "elapsed": 1209,
     "status": "ok",
     "timestamp": 1657118899558,
     "user": {
      "displayName": "su lin",
      "userId": "17083638299800112057"
     },
     "user_tz": -60
    },
    "id": "3HiqdtZoC8Sf"
   },
   "outputs": [],
   "source": [
    "dict_01 = {'loss': loss, 'loss_box_reg': loss_box_reg, 'loss_classifier': loss_clf, \n",
    "           'lr': lr, 'loss_val': loss_val, 'loss_box_reg_val': loss_box_reg_val, \n",
    "           'loss_classifier_val': loss_clf_val, 'loss_rpn_box': loss_rpn_box,\n",
    "          'loss_obj': loss_obj, 'loss_rpn_box_val': loss_rpn_box_val, 'loss_obj_val': loss_obj_val}\n",
    "df_training_log = pd.DataFrame(dict_01)\n",
    "df_training_log.to_csv('./training_log_FasterRCNN_resnet101_fpn_free_last2.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e054993",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_log = pd.read_csv('./training_log_FasterRCNN_resnet101_fpn_free_last2.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90aca27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import MaxNLocator\n",
    "epoch = np.arange(1,13,1)\n",
    "\n",
    "fig, ax = plt.subplots(2,2,figsize=(12, 12))\n",
    "ax[0, 0].set_xlim(1, 12)\n",
    "ax[0, 0].plot(epoch, df_training_log['loss'], label='Train Loss')\n",
    "ax[0, 0].plot(epoch, df_training_log['loss_val'], label='Validation Loss')\n",
    "ax[0, 0].set_title('Loss', fontsize=15)\n",
    "ax[0, 0].set_xlabel('Total Epoch', fontsize=12)\n",
    "ax[0, 0].legend()\n",
    "\n",
    "ax[0, 1].set_xlim(1, 12)\n",
    "ax[0, 1].plot(epoch, df_training_log['loss_box_reg'], color='c', \n",
    "              label='Train Bounding Box Regression Loss')\n",
    "ax[0, 1].plot(epoch, df_training_log['loss_box_reg_val'], color='m',\n",
    "              label='Validation Bounding Box Regression Loss')\n",
    "ax[0, 1].plot(epoch, df_training_log['loss_classifier'], color='c', \n",
    "              linestyle= 'dashdot', label='Train Classifier Loss')\n",
    "ax[0, 1].plot(epoch, df_training_log['loss_classifier_val'], color='m', \n",
    "              linestyle= 'dashdot', label='Validation Classifier Loss')\n",
    "ax[0, 1].set_title('Bounding Box Regression Loss and Classifier Loss', fontsize=15)\n",
    "ax[0, 1].set_xlabel('Epoch', fontsize=12)\n",
    "ax[0, 1].legend()\n",
    "\n",
    "ax[1, 0].set_xlim(1, 12)\n",
    "ax[1, 0].plot(epoch, df_training_log['loss_rpn_box'], color='c', \n",
    "              label='Train RPN Box Regression Loss')\n",
    "ax[1, 0].plot(epoch, df_training_log['loss_rpn_box_val'], color='m', \n",
    "              label='Validation RPN Box Regression Loss')\n",
    "ax[1, 0].plot(epoch, df_training_log['loss_obj'], color='c', \n",
    "              linestyle= 'dashdot', label='Train Objectness Loss')\n",
    "ax[1, 0].plot(epoch, df_training_log['loss_obj_val'], color='m',\n",
    "              linestyle= 'dashdot', label='Validation Objectness Loss')\n",
    "ax[1, 0].set_title('RPN Loss and Objectness Loss', fontsize=15)\n",
    "ax[1, 0].set_xlabel('Epoch', fontsize=12)\n",
    "ax[1, 0].legend()\n",
    "\n",
    "ax[1, 1].set_xlim(1, 12)\n",
    "ax[1, 1].plot(epoch, df_training_log['lr'], label='Learning Rate')\n",
    "ax[1, 1].set_title('Learning Rate', fontsize=15)\n",
    "ax[1, 1].set_xlabel('Epoch', fontsize=12)\n",
    "ax[1, 1].legend()\n",
    "fig.suptitle('Training Curves of Faster RCNN', fontsize=18)\n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "first_draft_torch.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
